{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data from Files, Writing Data to Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have learned about the different data types in python (integers, floats, booleans, strings), the different python data containers that can hold these data, whether those are native python containers (lists, tuples, dictionaries), or numpy arrays.  We will often encounter situations where we need to read data from a file into these containers, or write data in these containers to a file. This is a very common task in scientific computing that will  be covered in this notebook.\n",
    "\n",
    "In Python, text is stored in strings in **text files**. We learned about the string (`str`) data type in the Week2 lecture. By text we mean sequences of alphanumeric characters that make sense to a human. In contrast, there are also so-called **binary files** used for large data outputs, or executable programs, that can only be read by a computer program.\n",
    "\n",
    "There are several different ways to read and write text files in Python. We will cover the most common ones in turn which are: \n",
    "- Reading and writing files line-by-line\n",
    "- Reading and writing files directly into arrays using the `numpy` library\n",
    "- Reading and writing files using the `pandas` library\n",
    "\n",
    "There are of course many other ways to read and write files in Python, but these are arguably the most common and useful ones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `data/data_2MASS.txt` contains the magnitudes of some stars from the 2MASS astronomical sky survey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` text \n",
    "# Magnitudes of some stars from the 2MASS astronomical sky survey. \n",
    "# Coordinates are in decimal degrees in the J2000 equinox.\n",
    "#  RA          DEC          Name          Jmag   e_Jmag\n",
    "# (deg)       (deg)                       (mag)   (mag)\n",
    "10.684737 +41.269035 J00424433+4116085   9.453  0.052\n",
    "10.683469 +41.268585 J00424403+4116069   9.321  0.022\n",
    "10.685657 +41.269550 J00424455+4116103  10.773  0.069\n",
    "10.686026 +41.269226 J00424464+4116092   9.299  0.063\n",
    "10.683465 +41.269676 J00424403+4116108  11.507  0.056\n",
    "10.686015 +41.269630 J00424464+4116106   9.399  0.045\n",
    "10.685270 +41.267124 J00424446+4116016  12.070  0.035\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lines that start with `#` are comments that make up the file **header**. A header provides descriptive information or metadata (like units) about what is stored in the file and how it is arranged, but does not constitute the data itself. Then we see a table of data with 5 columns. The first two columns contain floating point numbers (floats) which are  the coordinates (right ascension and declination) of the star in decimal degrees. The third column is a string, which is name of the star.  The fourth and fifth columns also contain floats which represent the $J$-band magnitude of the star (`Jmag`), and the error on this measurement (`e_Jmag`). In Astronomy, the magnitude of a star is a logarithmic measure of its brightness (the $\\log_{10}$ of its intensity), and $J$ represents the astronomical filter that was used for the measurements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data from Files Line-by-Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already talked about several built-in Python data types (lists, tuples, dictionaries), but there are other types that we did not discuss. One of these is the file() object which can be used to read or write files. Let's try and access the contents of the data file in Python. We start off by creating a file object:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note if you are running this notebook on Google Colab**, you will need to download the data files first onto the Google drive file system, create the data and output directories and move the files to the data directory.  You can do this by running the following code snippet in a code cell:\n",
    "\n",
    "``` python\n",
    "import urllib.request\n",
    "url = \"https://raw.githubusercontent.com/enigma-igm/Phys29/main/Phys29/lectures/Week4/data/data_2MASS.txt\"\n",
    "urllib.request.urlretrieve(url, \"data_2MASS.txt\")\n",
    "url = \"https://raw.githubusercontent.com/enigma-igm/Phys29/main/Phys29/lectures/Week4/data/data_2MASS.csv\"\n",
    "urllib.request.urlretrieve(url,  \"data_2MASS.csv\")\n",
    "!mkdir -p data\n",
    "!mv -f data_2MASS.txt data\n",
    "!mv -f data_2MASS.csv data\n",
    "!mkdir -p output\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2MASS = open('data/data_2MASS.txt', 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The open function is taking the `data/data_2MASS.txt` file, opening it, and returning an object (which we call `f2MASS`) that can then be used to access the file contents. \n",
    "\n",
    "Note that f2MASS is not the data in the file, it is what is called a file handle, which points to the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(f2MASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we simply type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2MASS.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The read() function just read the whole file and put the contents inside a giant string. Let's try this again: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2MASS.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened? The output is an empty string `''`. We read the file, and the file **pointer** is now sitting at the end of the file, and hence there is nothing left to read. Let's now and try to do something more useful and capture the contents of the file in a string: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2MASS = open('data/data_2MASS.txt', 'r')\n",
    "string_data = f2MASS.read()\n",
    "f2MASS.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we opened the file, read the contents, and then closed the file. We can examine the contents of `string_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we instead use the print() function we get something that looks more like our file contents: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(string_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `string_data` is one giant string containing all the data in the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(string_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different lines are separated by the special character `\\n`, or the **newline** character, which is used to indicate the end of a line. The reason why the native Python print() function prints the contents of the file in a nice way is because it interprets the `\\n` character and prints a new line whenever it encounters it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This form of the data is not very useful. We want to access the data line-by-line.  There are multiple ways to do this, but the simplest and most common is to use a for loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/data_2MASS.txt', 'r') as f2MASS:\n",
    "    for line in f2MASS:\n",
    "        print(repr(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, what does the `with` statement do?  When you're reading a file in Python, you can use the `with` statement to handle the file. The `with` statement makes sure the file is properly opened before starting the block of code that follows, and then correctly closed after that block of code is done. After the code block executes that reads the file line-by-line it is no longer necessary to have the file open.  Whereas above we explicitly closed the file using the `f2MASS.close()` function when we were done, the `with` statement closes the file for us automatically.  By closing the file after the `with` block is completed, the code is easier to read. This also helps prevent bugs, like forgetting to close the file when you're done with it, which can lead to a program not exiting properly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, note that in our foor loop we are now looping over a file rather than a list, and this automatically reads in the next line at each iteration. In other words, the Python file object is an **iterator**.  Each line is being returned as a string as we execute the loop. When we print the string, we are using `repr()` to show any invisible characters. Notice the `\\n` newline character indicating the end of each line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're reading in a file line by line, what would be nice would be to get some values out of it.  Let's examine the last line in detail. If we just type `line` we should see the last line that was printed in the loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `split()` function to split the line into a list of strings. By default, the `split()` function splits on whitespace (spaces, tabs, newlines) so we don't need to worry about the exact number of spaces or the newline character `\\n` at the end of the line (there is a method called `strip()` that can be used to remove the newline character if needed, but we don't need that here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = line.split()\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if we want to access the data in the different columns, we can use the list indexing that we learned about in Week3. For example, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_ra = columns[0]\n",
    "this_dec = columns[1]\n",
    "this_name = columns[2]\n",
    "this_Jmag = columns[3]\n",
    "this_eJmag = columns[4]\n",
    "# Or equivalently, we could write\n",
    "# this_ra, this_dec, this_name, this_Jmag, this_eJmag = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_Jmag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that whereas this_name is a string, this_Jmag is actually a floating point number.  But because the file lines are stored as text, and read in as strings, and the `split()` function returns a list of strings, all of the data that we have just read in and split are strings.  We need to convert the strings to numbers if we want to do any calculations with them.  This can be done by casting the strings into floats using native Python `float()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_jmag = float(columns[3])\n",
    "this_jmag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you can see now that this_jmag is a floating point number rather than a string. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting everything we have learned about files, reading data, basic control flow, loops and numpy arrays together, we can now write a program that reads in the data from the file, converts them to the proper data types, stores them in numpy arrays, and then prints out the contents of the arrays to the screen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize empty lists\n",
    "ra_list = []\n",
    "dec_list = []\n",
    "name_list = []\n",
    "jmag_list = []\n",
    "e_jmag_list = []\n",
    "\n",
    "# Open the file\n",
    "with open('data/data_2MASS.txt', 'r') as file:\n",
    "    # Read and parse the lines\n",
    "    for line in file:\n",
    "        # Skip comment lines\n",
    "        if line.startswith('#'):\n",
    "            continue\n",
    "\n",
    "        # Split the line into columns\n",
    "        columns = line.split()\n",
    "\n",
    "        # Parse the columns and append to the lists\n",
    "        ra_list.append(float(columns[0]))\n",
    "        dec_list.append(float(columns[1]))\n",
    "        name_list.append(columns[2])\n",
    "        jmag_list.append(float(columns[3]))\n",
    "        e_jmag_list.append(float(columns[4]))\n",
    "\n",
    "# Convert the lists to arrays\n",
    "ra = np.array(ra_list)\n",
    "dec = np.array(dec_list)\n",
    "names = np.array(name_list)\n",
    "jmag = np.array(jmag_list)\n",
    "e_jmag = np.array(e_jmag_list)\n",
    "\n",
    "# Print the arrays\n",
    "print('RA:', ra)\n",
    "print('DEC:', dec)\n",
    "print('Name:', name_list)\n",
    "print('Jmag:', jmag)\n",
    "print('e_Jmag:', e_jmag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Data to Files Line-by-Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have read the data from a file, we might want to write the data to a new file. To open a file for writing we write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foutput = open('output/write_test.txt', 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then simply use the `write()` function to write any content to the file, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foutput.write(\"Hello, World!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to write multiple lines, you can either give a list of strings to the `writelines()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foutput.writelines(['spam\\n', 'egg\\n', 'foo\\n'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or you can write them as a single string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foutput.write('spam\\negg\\nfoo\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have finished writing data to a file, you need to close it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foutput.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now inspect the contents of the file we created using the terminal `cat` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat output/write_test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to when we put the block of code that dealt with reading data from a file behind the `with` statement, it is also conventional to put the writing code block behind a `with` statement.  \n",
    "As we have seen, files must not just be opened but should be properly closed afterwards to make sure they are actually written before using them somewhere else. Sometimes writes to files get cached by Python to minimize actual writing to disk, which is comparably slow. Closing a file ensures that these changes are actually written to disk. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting together what we have learned about writing files, we can now write out the contents of the arrays that we created above to a new file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file in write mode\n",
    "with open('output/output_2MASS.txt', 'w') as file:\n",
    "    # Write the header lines\n",
    "    file.write(\"# Magnitudes of some stars from the 2MASS astronomical sky survey.\\n\")\n",
    "    file.write(\"# Coordinates are in decimal degrees in the J2000 equinox.\\n\")\n",
    "    file.write(\"#  RA         DEC         Name               Jmag   e_Jmag\\n\")\n",
    "    file.write(\"# (deg)      (deg)                           (mag)   (mag)\\n\")\n",
    "\n",
    "    # Write the data line by line\n",
    "    for i in range(len(ra)):\n",
    "        line = \"{:10.6f} {:10.6f} {:<20s} {:7.3f}  {:.3f}\\n\".format(ra[i], dec[i], names[i], jmag[i], e_jmag[i])\n",
    "        file.write(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `with` statement opens the file and assigns it to the variable `file`, then we use the `write()` function to write the four lines of the file header. Finally, a for loop is used to write the contents of the arrays to the file line-by-line.  Note that we have explicitly specified the output format of each line of the output file, specifically the number of decimal places to use for the floating point numbers and the number of characters to write out for the strings.  There are a few different ways to specify the output format of data in python (see [here](https://docs.python.org/3/tutorial/inputoutput.html#fancier-output-formatting) for more details).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Writing Data Using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is a Python package that provides high-performance and easy to use data structures and data analysis tools. Specifically, pandas has useful utilities for reading and writing data from and to files. Below we provide examples of reading and writing data using pandas for the same data from the `data_2MASS.txt` file as above. Then we show how to use pandas to read and write data from and to a CSV file, which is a common file format for storing tabular data that has some advantages over the plain text files that we focused on for most of this lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read in the data from the `data_2MASS.txt` file using pandas, we use the `read_csv()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RA: [10.684737 10.683469 10.685657 10.686026 10.683465 10.686015 10.68527 ]\n",
      "DEC: [41.269035 41.268585 41.26955  41.269226 41.269676 41.26963  41.267124]\n",
      "Name: ['J00424433+4116085' 'J00424403+4116069' 'J00424455+4116103'\n",
      " 'J00424464+4116092' 'J00424403+4116108' 'J00424464+4116106'\n",
      " 'J00424446+4116016']\n",
      "Jmag: [ 9.453  9.321 10.773  9.299 11.507  9.399 12.07 ]\n",
      "e_Jmag: [0.052 0.022 0.069 0.063 0.056 0.045 0.035]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Use pd.read_csv to read the data from the file\n",
    "data = pd.read_csv('data/data_2MASS.txt', sep=r'\\s+', comment='#', \n",
    "                   names=['RA', 'DEC', 'Name', 'Jmag', 'e_Jmag'])\n",
    "\n",
    "# Extract the columns and convert to numpy arrays\n",
    "ra = data['RA'].values\n",
    "dec = data['DEC'].values\n",
    "names = data['Name'].values\n",
    "jmag = data['Jmag'].values\n",
    "e_jmag = data['e_Jmag'].values\n",
    "\n",
    "# Print the arrays\n",
    "print('RA:', ra)\n",
    "print('DEC:', dec)\n",
    "print('Name:', names)\n",
    "print('Jmag:', jmag)\n",
    "print('e_Jmag:', e_jmag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the name of the reading function `read_csv`, the abbreviation **CSV** stands for **comma-separated values**.  Wheras in our file `data_2MASS.txt` we separated the columns of data with spaces, in a CSV file the data entries are separated by commas.  To tell `pandas` that our data are separated with whitespaces of any length, we used the `sep=r'\\s+'` syntax, which is a **regular expression** that matches any number of whitespace characters (hence the `+`). We also used the `comment=#` syntax to tell `pandas` to ignore our header lines that start with the `#` character.  Finally, we input the names of the various columns in our data file using the `names=` syntax. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `read_csv()` function returns a pandas `DataFrame` object.  A `DataFrame`` is a 2-dimensional (rows $\\times$ columns) labeled data structure with columns of potentially different types. You can think of it like a spreadsheet, and it is the most commonly used pandas object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mType:\u001b[39m        DataFrame\n",
      "\u001b[31mString form:\u001b[39m\n",
      "RA        DEC               Name    Jmag  e_Jmag\n",
      "           0  10.684737  41.269035  J00424433+411 <...> 630  J00424464+4116106   9.399   0.045\n",
      "           6  10.685270  41.267124  J00424446+4116016  12.070   0.035\n",
      "\u001b[31mLength:\u001b[39m      7\n",
      "\u001b[31mFile:\u001b[39m        ~/miniconda3/envs/Phys29/lib/python3.12/site-packages/pandas/core/frame.py\n",
      "\u001b[31mDocstring:\u001b[39m  \n",
      "Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
      "\n",
      "Data structure also contains labeled axes (rows and columns).\n",
      "Arithmetic operations align on both row and column labels. Can be\n",
      "thought of as a dict-like container for Series objects. The primary\n",
      "pandas data structure.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
      "    Dict can contain Series, arrays, constants, dataclass or list-like objects. If\n",
      "    data is a dict, column order follows insertion-order. If a dict contains Series\n",
      "    which have an index defined, it is aligned by its index. This alignment also\n",
      "    occurs if data is a Series or a DataFrame itself. Alignment is done on\n",
      "    Series/DataFrame inputs.\n",
      "\n",
      "    If data is a list of dicts, column order follows insertion-order.\n",
      "\n",
      "index : Index or array-like\n",
      "    Index to use for resulting frame. Will default to RangeIndex if\n",
      "    no indexing information part of input data and no index provided.\n",
      "columns : Index or array-like\n",
      "    Column labels to use for resulting frame when data does not have them,\n",
      "    defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\n",
      "    will perform column selection instead.\n",
      "dtype : dtype, default None\n",
      "    Data type to force. Only a single dtype is allowed. If None, infer.\n",
      "copy : bool or None, default None\n",
      "    Copy data from inputs.\n",
      "    For dict data, the default of None behaves like ``copy=True``.  For DataFrame\n",
      "    or 2d ndarray input, the default of None behaves like ``copy=False``.\n",
      "    If data is a dict containing one or more Series (possibly of different dtypes),\n",
      "    ``copy=False`` will ensure that these inputs are not copied.\n",
      "\n",
      "    .. versionchanged:: 1.3.0\n",
      "\n",
      "See Also\n",
      "--------\n",
      "DataFrame.from_records : Constructor from tuples, also record arrays.\n",
      "DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n",
      "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      "read_table : Read general delimited file into DataFrame.\n",
      "read_clipboard : Read text from clipboard into DataFrame.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Please reference the :ref:`User Guide <basics.dataframe>` for more information.\n",
      "\n",
      "Examples\n",
      "--------\n",
      "Constructing DataFrame from a dictionary.\n",
      "\n",
      ">>> d = {'col1': [1, 2], 'col2': [3, 4]}\n",
      ">>> df = pd.DataFrame(data=d)\n",
      ">>> df\n",
      "   col1  col2\n",
      "0     1     3\n",
      "1     2     4\n",
      "\n",
      "Notice that the inferred dtype is int64.\n",
      "\n",
      ">>> df.dtypes\n",
      "col1    int64\n",
      "col2    int64\n",
      "dtype: object\n",
      "\n",
      "To enforce a single dtype:\n",
      "\n",
      ">>> df = pd.DataFrame(data=d, dtype=np.int8)\n",
      ">>> df.dtypes\n",
      "col1    int8\n",
      "col2    int8\n",
      "dtype: object\n",
      "\n",
      "Constructing DataFrame from a dictionary including Series:\n",
      "\n",
      ">>> d = {'col1': [0, 1, 2, 3], 'col2': pd.Series([2, 3], index=[2, 3])}\n",
      ">>> pd.DataFrame(data=d, index=[0, 1, 2, 3])\n",
      "   col1  col2\n",
      "0     0   NaN\n",
      "1     1   NaN\n",
      "2     2   2.0\n",
      "3     3   3.0\n",
      "\n",
      "Constructing DataFrame from numpy ndarray:\n",
      "\n",
      ">>> df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
      "...                    columns=['a', 'b', 'c'])\n",
      ">>> df2\n",
      "   a  b  c\n",
      "0  1  2  3\n",
      "1  4  5  6\n",
      "2  7  8  9\n",
      "\n",
      "Constructing DataFrame from a numpy ndarray that has labeled columns:\n",
      "\n",
      ">>> data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n",
      "...                 dtype=[(\"a\", \"i4\"), (\"b\", \"i4\"), (\"c\", \"i4\")])\n",
      ">>> df3 = pd.DataFrame(data, columns=['c', 'a'])\n",
      "...\n",
      ">>> df3\n",
      "   c  a\n",
      "0  3  1\n",
      "1  6  4\n",
      "2  9  7\n",
      "\n",
      "Constructing DataFrame from dataclass:\n",
      "\n",
      ">>> from dataclasses import make_dataclass\n",
      ">>> Point = make_dataclass(\"Point\", [(\"x\", int), (\"y\", int)])\n",
      ">>> pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n",
      "   x  y\n",
      "0  0  0\n",
      "1  0  3\n",
      "2  2  3\n",
      "\n",
      "Constructing DataFrame from Series/DataFrame:\n",
      "\n",
      ">>> ser = pd.Series([1, 2, 3], index=[\"a\", \"b\", \"c\"])\n",
      ">>> df = pd.DataFrame(data=ser, index=[\"a\", \"c\"])\n",
      ">>> df\n",
      "   0\n",
      "a  1\n",
      "c  3\n",
      "\n",
      ">>> df1 = pd.DataFrame([1, 2, 3], index=[\"a\", \"b\", \"c\"], columns=[\"x\"])\n",
      ">>> df2 = pd.DataFrame(data=df1, index=[\"a\", \"c\"])\n",
      ">>> df2\n",
      "   x\n",
      "a  1\n",
      "c  3"
     ]
    }
   ],
   "source": [
    "data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One nice thing about pandas `DataFrames` is that they display nicely in Jupyter notebooks.  Let's take a look at the DataFrame that we just created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "RA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DEC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Jmag",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "e_Jmag",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6b880252-79b8-466a-a783-0235a6952323",
       "rows": [
        [
         "0",
         "10.684737",
         "41.269035",
         "J00424433+4116085",
         "9.453",
         "0.052"
        ],
        [
         "1",
         "10.683469",
         "41.268585",
         "J00424403+4116069",
         "9.321",
         "0.022"
        ],
        [
         "2",
         "10.685657",
         "41.26955",
         "J00424455+4116103",
         "10.773",
         "0.069"
        ],
        [
         "3",
         "10.686026",
         "41.269226",
         "J00424464+4116092",
         "9.299",
         "0.063"
        ],
        [
         "4",
         "10.683465",
         "41.269676",
         "J00424403+4116108",
         "11.507",
         "0.056"
        ],
        [
         "5",
         "10.686015",
         "41.26963",
         "J00424464+4116106",
         "9.399",
         "0.045"
        ],
        [
         "6",
         "10.68527",
         "41.267124",
         "J00424446+4116016",
         "12.07",
         "0.035"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 7
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RA</th>\n",
       "      <th>DEC</th>\n",
       "      <th>Name</th>\n",
       "      <th>Jmag</th>\n",
       "      <th>e_Jmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.684737</td>\n",
       "      <td>41.269035</td>\n",
       "      <td>J00424433+4116085</td>\n",
       "      <td>9.453</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.683469</td>\n",
       "      <td>41.268585</td>\n",
       "      <td>J00424403+4116069</td>\n",
       "      <td>9.321</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.685657</td>\n",
       "      <td>41.269550</td>\n",
       "      <td>J00424455+4116103</td>\n",
       "      <td>10.773</td>\n",
       "      <td>0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.686026</td>\n",
       "      <td>41.269226</td>\n",
       "      <td>J00424464+4116092</td>\n",
       "      <td>9.299</td>\n",
       "      <td>0.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.683465</td>\n",
       "      <td>41.269676</td>\n",
       "      <td>J00424403+4116108</td>\n",
       "      <td>11.507</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.686015</td>\n",
       "      <td>41.269630</td>\n",
       "      <td>J00424464+4116106</td>\n",
       "      <td>9.399</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.685270</td>\n",
       "      <td>41.267124</td>\n",
       "      <td>J00424446+4116016</td>\n",
       "      <td>12.070</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          RA        DEC               Name    Jmag  e_Jmag\n",
       "0  10.684737  41.269035  J00424433+4116085   9.453   0.052\n",
       "1  10.683469  41.268585  J00424403+4116069   9.321   0.022\n",
       "2  10.685657  41.269550  J00424455+4116103  10.773   0.069\n",
       "3  10.686026  41.269226  J00424464+4116092   9.299   0.063\n",
       "4  10.683465  41.269676  J00424403+4116108  11.507   0.056\n",
       "5  10.686015  41.269630  J00424464+4116106   9.399   0.045\n",
       "6  10.685270  41.267124  J00424446+4116016  12.070   0.035"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to note that whereas in our line-by-line file reading example above we had to explicitly convert the strings to floating point numbers, pandas has automatically done this for us.  This is because pandas is *smart* enough to recognize that the columns of data in our file are floating point numbers.  We can check the data types of the columns in our DataFrame using the `dtype` attribute: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RA        float64\n",
       "DEC       float64\n",
       "Name       object\n",
       "Jmag      float64\n",
       "e_Jmag    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The string names of the stars are stored in the colum `Name` and have data type `object`, which is the pandas data type for strings.  The rest of the data columns have data type `float64`, which we expect. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see `pandas` can read the data in our file `data_2MASS.txt` into a `DataFrame` object, but we had to provide it with a lot of guidance via the keyword arguments to `read_csv`. An alternative would be to use a more standarized file format for storing the data, namely the CSV standard. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `data_2MASS.csv` contains the same data as the `data_2MASS.txt` file, but in CSV format. It looks like this:\n",
    "\n",
    "``` text\n",
    "# Magnitudes of some stars from the 2MASS astronomical sky survey. \n",
    "# Coordinates are in decimal degrees in the J2000 equinox.\n",
    "# Units: RA (deg), DEC (deg), Name, Jmag (mag), e_Jmag (mag)\n",
    "RA,DEC,Name,Jmag,e_Jmag\n",
    "10.684737,+41.269035,00424433+4116085,9.453,0.052\n",
    "10.683469,+41.268585,00424403+4116069,9.321,0.022\n",
    "10.685657,+41.269550,00424455+4116103,10.773,0.069\n",
    "10.686026,+41.269226,00424464+4116092,9.299,0.063\n",
    "10.683465,+41.269676,00424403+4116108,11.507,0.056\n",
    "10.686015,+41.269630,00424464+4116106,9.399,0.045\n",
    "10.685270,+41.267124,00424446+4116016,12.070,0.035\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first (non-comment) line of the file contains the names of the columns, and the data entries are separated by commas.  This is the standard format for a CSV file.\n",
    "\n",
    "We can now read in the data from the `data_2MASS.csv` file using the `pandas` `read_csv()` function. Notice the syntax is quite a bit simpler now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RA        float64\n",
       "DEC       float64\n",
       "Name       object\n",
       "Jmag      float64\n",
       "e_Jmag    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use pd.read_csv to read the data from the file\n",
    "data = pd.read_csv('data/data_2MASS.csv', comment='#')\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RA: [10.684737 10.683469 10.685657 10.686026 10.683465 10.686015 10.68527 ]\n",
      "DEC: [41.269035 41.268585 41.26955  41.269226 41.269676 41.26963  41.267124]\n",
      "Name: ['00424433+4116085' '00424403+4116069' '00424455+4116103'\n",
      " '00424464+4116092' '00424403+4116108' '00424464+4116106'\n",
      " '00424446+4116016']\n",
      "Jmag: [ 9.453  9.321 10.773  9.299 11.507  9.399 12.07 ]\n",
      "e_Jmag: [0.052 0.022 0.069 0.063 0.056 0.045 0.035]\n"
     ]
    }
   ],
   "source": [
    "# Assign the pandas columns to numpy arrays as before\n",
    "ra = data['RA'].values\n",
    "dec = data['DEC'].values\n",
    "names = data['Name'].values\n",
    "jmag = data['Jmag'].values\n",
    "e_jmag = data['e_Jmag'].values\n",
    "\n",
    "# Print the arrays\n",
    "print('RA:', ra)\n",
    "print('DEC:', dec)\n",
    "print('Name:', names)\n",
    "print('Jmag:', jmag)\n",
    "print('e_Jmag:', e_jmag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what about writing data to a file using Pandas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas DataFrame from our numpy arrays\n",
    "df = pd.DataFrame({\n",
    "    'RA': ra,\n",
    "    'DEC': dec,\n",
    "    'Name': names,\n",
    "    'Jmag': jmag,\n",
    "    'e_Jmag': e_jmag\n",
    "})\n",
    "\n",
    "# Define the header\n",
    "header = (\"# Magnitudes of some stars from the 2MASS astronomical sky survey.\\n\"\n",
    "          \"# Coordinates are in decimal degrees in the J2000 equinox.\\n\"\n",
    "          \"#  RA         DEC         Name               Jmag   e_Jmag\\n\"\n",
    "          \"# (deg)      (deg)                           (mag)   (mag)\\n\")\n",
    "\n",
    "# Write the header to the file. Pandas does not support writing these # delimited headers, so we have to do it manually.\n",
    "with open('output/output_with_header.csv', 'w') as f:\n",
    "    f.write(header)\n",
    "# Write the DataFrame to a file. Notice that we use the mode='a' option to append to the file, \n",
    "# since we already created a new file for writing when we wrote the header\n",
    "df.to_csv('output/output_with_header.csv', mode='a', index=False, float_format=\"%.6f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CSV format default is to write out an extra column at the beginning indicating the index of each line. Since we just wanted the data values, we suppressed this with `index=False`. Alternativey, without writing out the header information, writing a CSV file is even simpler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the DataFrame to a file\n",
    "df.to_csv('output/output_no_header.csv', index=False, float_format=\"%.6f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now check that we wrote a valid CSV file by reading it back in using `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_header = pd.read_csv('output/output_with_header.csv', comment='#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_header = pd.read_csv('output/output_no_header.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Writing Data Using NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `numpy` package also has methods to read and write data. We provide examples of reading using `np.loadtxt` and writing using `np.savetxt` using the same data from the `data_2MASS.txt` file as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Use np.loadtxt to read the data from the file\n",
    "data = np.loadtxt('data/data_2MASS.txt', dtype={'names': ('RA', 'DEC', 'Name', 'Jmag', 'e_Jmag'),\n",
    "                                           'formats': ('f8', 'f8', 'S20', 'f8', 'f8')})\n",
    "\n",
    "# Extract the columns\n",
    "ra = data['RA']\n",
    "dec = data['DEC']\n",
    "names = data['Name'].astype(str)\n",
    "jmag = data['Jmag']\n",
    "e_jmag = data['e_Jmag']\n",
    "\n",
    "# Print the arrays\n",
    "print('RA:', ra)\n",
    "print('DEC:', dec)\n",
    "print('Name:', names)\n",
    "print('Jmag:', jmag)\n",
    "print('e_Jmag:', e_jmag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a structured array with your data. We do this becuase we have data with different types. \n",
    "# Another option would have been to cast everything to dtype=str (U20) and use np.column_stack\n",
    "data = np.zeros(len(ra), dtype={'names':('RA', 'DEC', 'Name', 'Jmag', 'e_Jmag'),\n",
    "                                 'formats':('f8', 'f8', 'U20', 'f8', 'f8')})\n",
    "\n",
    "data['RA'] = ra\n",
    "data['DEC'] = dec\n",
    "data['Name'] = names\n",
    "data['Jmag'] = jmag\n",
    "data['e_Jmag'] = e_jmag\n",
    "\n",
    "# Define the header and footer\n",
    "header = (\"# Magnitudes of some stars from the 2MASS astronomical sky survey.\\n\"\n",
    "          \"# Coordinates are in decimal degrees in the J2000 equinox.\\n\"\n",
    "          \"#  RA         DEC      Name                  Jmag     e_Jmag\\n\"\n",
    "          \"# (deg)      (deg)                           (mag)    (mag)\")\n",
    "\n",
    "# Define the format for each field\n",
    "formats = \"%10.6f %10.6f %-20s %7.3f  %7.3f\"\n",
    "\n",
    "# Write the data to the file\n",
    "np.savetxt('output/output_numpy.txt', data, fmt=formats, header=header, comments='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Phys29",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
