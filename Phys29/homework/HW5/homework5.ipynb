{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 32px; text-align: center;\">Introduction to Computer Programming for the Physical Sciences</h1>\n",
    "<h2 style=\"font-size: 24px; text-align: center;\">Joseph F. Hennawi</h2>\n",
    "<h3 style=\"font-size: 24px; text-align: center;\">Spring 2025</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul style=\"list-style: none;\">\n",
    "  <li style=\"margin-bottom: 10px; font-size: 20px;\"><span style=\"display: inline-block; width: 10px; height: 10px; border: 2px solid black; margin-right: 10px;\"></span>Open a new Jupyter notebook</li>\n",
    "  <li style=\"margin-bottom: 10px; font-size: 20px;\"><span style=\"display: inline-block; width: 10px; height: 10px; border: 2px solid black; margin-right: 10px;\"></span>Name your notebook with your name and Homework 1</li>\n",
    "  <li style=\"margin-bottom: 10px; font-size: 20px;\"><span style=\"display: inline-block; width: 10px; height: 10px; border: 2px solid black; margin-right: 10px;\"></span>Open a Markdown cell at the top and write your name and Homework 5</li>\n",
    "  <li style=\"margin-bottom: 10px; font-size: 20px;\"><span style=\"display: inline-block; width: 10px; height: 10px; border: 2px solid black; margin-right: 10px;\"></span>Open a Markdown cell before each problem and write e.g. Problem 1, Problem 2(a), etc.</li>\n",
    "  <li style=\"margin-bottom: 10px; font-size: 20px;\"><span style=\"display: inline-block; width: 10px; height: 10px; border: 2px solid black; margin-right: 10px;\"></span>Please abide by the <b><a href=\"https://github.com/enigma-igm/Phys29/blob/main/using_AI_tools.md\">Policy and Guidelines on Using AI Tools</a></b></li>\n",
    "  <li style=\"margin-bottom: 10px; font-size: 20px;\"><span style=\"display: inline-block; width: 10px; height: 10px; border: 2px solid black; margin-right: 10px;\"></span>Once you finish the problems: 1) Restart the Python kernel and clear all cell outputs. 2) Rerun the notebook from start to finish so that all answers/outputs show up. 3) Save your notebook as a single .pdf file and upload it to Gradescope on Canvas by the deadline.</li>\n",
    "  <li style=\"margin-bottom: 10px; font-size: 20px;\"><span style=\"display: inline-block; width: 10px; height: 10px; border: 2px solid black; margin-right: 10px;\"></span> For parts of problems that require analytical solutions you can perform your calculations using a pencil and paper. Then  photograph your work and convert the photograph to a .pdf file using an online tool. Homework assignments can only be submitted as a single .pdf file, so you will also need to figure out how to concatenate your photo .pdf file and your notebook .pdf file into a single .pdf file that you can submit. Online websites can do this for you. Alternatively, you can code up the analytical solution to your problems in a notebook Markdown cell using the LaTeX mathematical rendering language. This is harder but a chatbot can help you learn it. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Riemann Sums\n",
    "\n",
    "In the Week6 lecture we will learn how to numerically integrate functions in Python. You may find it helpful to consult those [lecture notes](https://github.com/enigma-igm/Phys29/blob/main/Phys29/lectures/Week6/02_integration.ipynb) for this problem.  You are all familiar with the concept that an integral \n",
    "$$ \n",
    "I = \\int_a^b f(x) dx\n",
    "$$ \n",
    "is simply the area under the curve $f(x)$ between $x=a$ and $x=b$. You are probably also familiar with the definition of a Riemann integral \n",
    "that approximates this area as a finite sum of vertical rectangular strips, and then taking the limit as the width of the strips goes to zero\n",
    "(you can read more at the Wikipedia article on [Riemann sums](https://en.wikipedia.org/wiki/Riemann_sum)). \n",
    "If we use $n$ strips of equal width $\\Delta x = (b-a)/n$, then the Riemann integral can be defined as \n",
    "$$\n",
    "I \\approx \\sum_{i=1}^n f(a + i \\Delta x/2) \\Delta x\n",
    "$$\n",
    "where $f(a + i \\Delta x/2)$ is the value of the function $f(x)$ at the midpoint of the $i$ th strip. In other words, we are using the so-called\n",
    "**midpoint** rule whereby one evaluates the function, $f(x)$, at the midpoint of each interval, which determines the height of each rectangle.\n",
    "\n",
    "**a)** Write a function to evaluate Riemann sums that is consistent with the docstring below. **No loops are allowed anywhere in your implementation!**\n",
    "\n",
    "\n",
    "```python\n",
    "def riemann_sum(func, a, b, n=15, plot=True):\n",
    "    \"\"\"\n",
    "    Compute the Riemann sum of func(x) over the interval [a, b] with n subintervals using the midpoint rule.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    func : callable \n",
    "        The function to integrate, with calling sequence func(x).\n",
    "    a : float\n",
    "        The lower limit of integration.\n",
    "    b : float\n",
    "        The upper limit of integration.\n",
    "    n : int, optional\n",
    "        The number of subintervals to use. Default is 15.\n",
    "    plot : bool, optional\n",
    "        If True, plot the function func(x) over the interval [a, b] (using a finely spaced array of x-values), as well as the rectangles \n",
    "        used to compute the Riemann sum and the midpoints.  Default is True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    answer : float\n",
    "        The estimate of the integral of func(x) over the interval [a, b].\n",
    "\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "**b)**\n",
    "Use your `riemann_sum` function to numerically evaluate the following two definite integrals:\n",
    "$$\n",
    "\\int_0^\\pi \\sin(x) dx = 2  \\quad\\quad \\text{and} \\quad\\quad \\int_{-1}^2 x^3 dx = \\frac{15}{4}. \n",
    "$$\n",
    "for the default value of `n=15`. For each integral, print the numerical result, the exact result, and the relative error between the two to the screen. Run your function with `plot=True` for both cases. An example of how the plot should look for the case of $\\int_{-1}^{1} x^2 dx = \\frac{2}{3}$ is shown below. Make sure your plot looks the same!\n",
    "\n",
    "<img src=\"figures/riemann_sum.png\"/>\n",
    "\n",
    "**c)** Obviously the accuracy of the Riemann sum depends on the number of subintervals chosen $n$. One can show that the *absolute error*,  $\\epsilon_{\\rm abs}(n)$, of an integral approximated with Riemann sums scales like: \n",
    "$$\n",
    "\\epsilon_{\\rm abs}(n) \\equiv \\left| I(n) -\\int_a^b f(x) dx \\right| \\propto n^{\\alpha}\n",
    "$$\n",
    "where $\\alpha$ is a constant.  For the case of $\\int_0^\\pi \\sin(x) dx = 2$, use your function to compute the Rieman sum for $n=10, 100, 1000, 10000, 100000$ and store your results in a `numpy` array or a list. I strongly recommend that you set `plot=False` in your calls to `riemann_sum` for this step! Make a **scatter** plot, i.e. where the data are shown as **points, not a curve!**,  of the absolute error $\\epsilon_{\\rm abs}(n)$ as a function of $n$ with logarithmic x and y axes. From your scatter plot of the data, estimate the value of $\\alpha$ and overplot a curve with $g(n)=A n^\\alpha$, where the constant $A$ is chosen to roughly go through your data points (just estimate a value by eye, no need to perform a fit). Make sure you label your coordinate axes and include a legend. You are allowed to use a loop over $n$ for this step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Blackbody Radiation\n",
    "\n",
    "A *blackbody* is a physics idealization of a body in which electromagnetic radiation has come into perfect thermal equilibrium with the body, both of which can \n",
    "therefore be characterized by a  temperature $T$, assumed to be measured on the absolute (Kelvin) scale. Your own body radiates mostly infrared photons that are \n",
    "approximately blackbody in nature,  and the Sun radiates mostly optical photons that are also approximately blackbody in nature. The frequency spectrum of the \n",
    "radiation emitted by a blackbody of temperature $T$ is given by\n",
    "$$\n",
    "F(\\nu) = \\frac{2\\pi h\\nu^3}{c^2} \\frac{1}{\\exp(h\\nu/k_{\\rm B}T) - 1}\n",
    "$$\n",
    "where $h$ is Planck's constant, $\\nu$ is the photon frequency, $c$ is the speed of light, and $k_{\\rm B}$ is Boltzmann's constant. The quantity $F(\\nu) d\\nu$ is the\n",
    "radiation flux (power per unit area) emitted within the frequency range $\\nu$ to $\\nu + d\\nu$. Therefore $F(\\nu)$ has SI units of ${\\rm W/m^2/Hz}$.\n",
    "\n",
    "**a)** By Taylor expanding the exponential term in the denominator of the above expression, show that in the low frequency limit $h\\nu \\ll k_{\\rm B}T$ the radiation \n",
    "flux has a power-law dependendce on frequency. What is that power-law index? This is known as the *Rayleigh-Jeans* spectrum, and is what classical physics predicted for the spectrum before the advent of quantum mechanics. You should see that Planck's constant does not appear in your answer (hence there is no quantum physics in this description). \n",
    "\n",
    "**b)** Write a Python function that takes as input the temperature $T$ and a `numpy` array of frequencies $\\nu$ and returns a `numpy` array which is the radiation flux $F(\\nu)$. \n",
    "\n",
    "**c)** Using your function from part **b)** plot the spectrum (i.e. $F(\\nu)$ vs. $\\nu$) for the case of $T = 310.15\\,{\\rm K}$ (human body temperature) and $T = 5778\\,{\\rm K}$ (Sun's surface temperature) *on the same plot*.  \n",
    "Given the large dynamic range of frequency, $\\nu$, that you will need to visualize you should evaluate this function using a `numpy` array of **logarithmically spaced** $\\nu$ values.\n",
    "Your plot\n",
    "should have the following set of characteristics:\n",
    "- Different colors for the curves illustrating the two different temperatures.\n",
    "- Labels on the $x$ and $y$ axes (specifying units). \n",
    "- A legend indicating the two different curves. \n",
    "- Clearly illustrate the behavior at low and high frequencies. This requires a sufficiently large range of frequencies and logarithmic axes for both the $x$ and $y$ axes.\n",
    "- A secondary $x$-axis at the top of the plot that shows the wavelength $\\lambda = c/\\nu$ in microns, $\\mu{\\rm m}$. Recall that $1\\mu{\\rm m} = 10^{-6}{\\rm m}$.\n",
    "- A reference curve shown as a black dashed-line that shows the Rayleigh-Jeans power-law behavior that you derived for the low frequency limit in part **a)**. Assume the Sun's surface temperature, $T=5778\\,{\\rm K}$, for plotting this Rayleigh-Jeans power-law curve. \n",
    "\n",
    "**d)** Is the low-frequency behavior of the spectrum consistent with the Rayleigh-Jeans power-law you derived in part **a)**? Does the human body spectral flux ever exceed that of the Sun at any frequency?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: Distribution of Household Size and Income in the US\n",
    "\n",
    "The [American Community Survey](https://www.census.gov/programs-surveys/acs) (ACS) is a yearly survey conducted by the United States Census Bureau that collects information about the country and its inhabitants.  Download the file [census_income_data.csv](https://github.com/enigma-igm/Phys29/blob/main/Phys29/homework/HW5/data/census_income_data_2022.csv) at this link: https://github.com/enigma-igm/Phys29/blob/main/Phys29/homework/HW5/data/census_income_data_2022.csv This is a comma-separated values or **csv** file containing household income data from the ACS. \n",
    "\n",
    "As you can see from the header, it has three columns, `WGTP`, `NPF`, and `HINCP`: \n",
    "- `WGTP` is the weight of the household, or the number of such households in the US population\n",
    "- `NPF` is the number of people in the household\n",
    "- `HINCP` is the household income\n",
    "\n",
    "The `WGTP` is a statistical weight that is assigned to each record (line of the file) that indicates how many people in the population are represented by that record.  In yearly surveys like the ACS, it's not feasible to collect data from every individual in the population, so a subset of the population is surveyed instead.  Each record in the datafile thus represents (or \"stands in for\") a certain number of similar individuals in the population. The WGTP value tells you how many individuals that record represents.\n",
    "\n",
    "For example a line in the file like:\n",
    "```\n",
    "WGTP, NPF, HINCP\n",
    "127, 5, 75000\n",
    "```\n",
    "indicates that in the USA there are 127 households with 5 members per household in them which earn a yearly household income of $75,000. \n",
    "\n",
    "In this problem we want to analyze the distribution of household size and household income in the U.S. population. Given the way that the data is collected, we need to use the WGTP values to get accurate estimates of the distribution across the population. For example, if you want to calculate the total number of households: \n",
    "$$\n",
    "N_{\\rm households} = \\sum_i {\\rm WGTP}_i\n",
    "$$\n",
    "where the sum is over all records in the datafile. \n",
    "\n",
    "Similarly, to calculate the total population of the USA, you would sum up the product of the WGTP (# of similar housholds in USA) and NPF (# of family members per household) values:\n",
    "$$\n",
    "N_{\\rm people} = \\sum_i {\\rm WGTP}_i \\times {\\rm NPF}_i. \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Read in the datafile into a `pandas` DataFrame `df`. Run the `df.describe()` method on the DataFrame to get a sense of the values in the data. \n",
    "\n",
    "**b)** Assign the `WGTP`, `NPF`, and `HINCP` columns to `numpy` arrays. Calculate the total number of households and the total number of people in the US population using the formulas above.  Print the results to the screen. Do the numbers you get make sense?\n",
    "\n",
    "**c)** According to your result from `df.describe()`, the household income column, `HINCP`, contains negative values. These correspond to households that had a net loss in 2022. For example, suppose a household member owns a business that suffered a loss in 2022 (the business expenses exceeded business income), this would corresopnd to a net negative income. Use `numpy` boolean array indexing to create a new filtered dataset that only includes the records with a net positive household income, i.e. `HINCP > 0`. Recompute the total number of households and the total number of people in the US population using this filtered dataset and print the results to the screen. Use this filtered dataset for all the remaining parts of this problem.\n",
    "\n",
    "**d)** In lecture we learned how `matplotlib` histograms can be used to visualize the distribution in a dataset. Use the `matplotlib` library to create a histogram of the number of persons per household, `NPF` in the dataset. Choose linearly spaced bins of unit width from the minimum value of the `NPF` to the maximum value (make sure your bins include the minimum and maximum value). The $y$-axis of your histogram **should be the percentage of the total number of housholds** contained in each bin, where the total number of households is the number you calculated in part **c)**. Note that you cannot simply run `plt.hist(NPF, bins=bins)` or `np.histogram(NPF, bins=bins)` because the `WGTP` values need to be taken into account. The `plt.hist` and `np.histogram` functions have a `weights` argument that you can use to construct a weighted histogram and thus factor in the weights. Use the arrays returned by the histogram function to explicitly verify that the sum of the percentages over all the bins is equal to 100%, and print this to the screen. \n",
    "\n",
    "**e)** Create and plot a histogram of the household income, `HINCP` in the dataset, again taking proper account of the `WGTP` weights.  Choose linearly spaced bins of width $\\$20000$ spanning from $\\$0$ to $\\$2,500,000$. As in part **d)**, the $y$-axis should be the percentage of the total number of housholds contained in each bin. Choose a linear scaling for both the $x$-axis and $y$-axis.  Again, verify that the sum of the percentages over all the bins is equal to 100%, and print this to the screen. \n",
    "\n",
    "**f)** Remake the plot from part **e)** but using a logarithmic scale for the $y$-axis. Which scale do you think is more informative, linear or log?\n",
    "\n",
    "**g)** For the household income histogram, write code that uses the arrays returned to print to the screen the bin index (zero based), the left edge of the bin, the right edge of the bin, and the percentage (up to six decimal places) of the total number of households contained in each bin. \n",
    "\n",
    "**f)** From the `numpy` array that contains the household income histogram output (i.e. what `np.histogram` or `plt.hist` return), compute the **total percentage** of households with an income **greater than or equal to** $\\$500,000$ and print this to the screen.\n",
    "\n",
    "**g)** From the `numpy` arrays that contain the US census data (i.e. `WGPT`, `HINCP` etc.), directly compute the the **total percentage** of households with an income **greater than or equal to** $\\$500,000$ and print this to the screen.  **Note that you are not allowed to use your histogram outputs for this step**, i.e. your code needs to operate on the census data `numpy` arrays directly.  Verify that that the two percentages you computed in parts **f)** and **g)** are in agreement with each other. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
